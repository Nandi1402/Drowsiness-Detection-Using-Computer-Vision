```markdown
# ğŸš— Drowsiness Detection in Drivers

A computer vision + deep learning project that detects driver drowsiness in real time to help prevent accidents caused by fatigue.

---

## ğŸ“– Overview
Driver fatigue is a major contributor to road accidents worldwide. This project uses **Convolutional Neural Networks (CNNs)** and **computer vision** to monitor facial cuesâ€”eye closure, blink rate, and yawningâ€”and raise an alert when drowsiness is detected.  
If youâ€™re using the full pipeline, it can combine classic detectors (Haar/Viola-Jones) with deep models (e.g., CNNs, MobileNet/VGG variants, or YOLO for face/eye ROI).

---

## âœ¨ Features
- Real-time webcam/video stream analysis with **OpenCV**
- Eye & mouth region detection (blink and yawn cues)
- Deep learning classifier for **alert vs. drowsy**
- Audible alert when drowsiness is detected
- Modular code to swap detectors/models (Haar, Dlib, YOLO, CNN)

---

## ğŸ› ï¸ Tech Stack
- **Python 3.8+**
- **OpenCV** â€“ video & image processing
- **TensorFlow / Keras** â€“ training & inference
- **Dlib** or **Haar Cascades** â€“ facial landmarks / classical detection (optional)
- **NumPy, Pandas** â€“ data utilities
- **Matplotlib** â€“ visualization (optional)

---

## ğŸ“‚ Project Structure
```

drowsiness-detection/
â”œâ”€â”€ data/               # Datasets (eyes open/closed, yawning frames, etc.)
â”œâ”€â”€ models/             # Saved weights/checkpoints
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ detector.py     # Main real-time detection script
â”‚   â”œâ”€â”€ train.py        # Model training / fine-tuning script
â”‚   â”œâ”€â”€ utils.py        # Helpers: preprocessing, alerts, metrics, etc.
â”‚   â”œâ”€â”€ configs/        # (Optional) YAML/JSON configs for experiments
â”œâ”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ LICENSE             # Project license (MIT by default)
â””â”€â”€ README.md           # You are here

````

---

## ğŸš€ Getting Started

### 1) Clone the repo
```bash
git clone https://github.com/<your-username>/drowsiness-detection.git
cd drowsiness-detection
````

### 2) (Recommended) Create a virtual environment

```bash
python -m venv .venv
# Windows
.venv\Scripts\activate
# macOS/Linux
source .venv/bin/activate
```

### 3) Install dependencies

```bash
pip install -r requirements.txt
```

> If you face `dlib` build issues, you may skip it and use Haar cascades or prebuilt wheels for your OS.

### 4) Run real-time detection

```bash
python src/detector.py
```

> By default, this reads from your primary webcam (`cv2.VideoCapture(0)`).
> To run on a video file: `python src/detector.py --video path/to/video.mp4`

---

## âš™ï¸ Configuration (Optional)

You can pass CLI flags or config files:

```bash
python src/detector.py \
  --model_path models/cnn_best.h5 \
  --use_haar true \
  --threshold 0.6 \
  --alarm_sound assets/alarm.wav
```

Common flags:

* `--model_path`: path to trained model
* `--use_haar` / `--use_dlib` / `--use_yolo`: choose detector(s)
* `--threshold`: drowsiness probability threshold for alerts
* `--video`: input video path (omit for webcam)
* `--alarm_sound`: custom alert sound file

---

## ğŸ“Š Dataset

You can use open datasets or collect your own:

* Eye state datasets (open/closed)
* Yawn/mouth state datasets

**Tips for data quality**

* Balance classes (alert vs. drowsy)
* Include varied lighting, head poses, glasses/no-glasses
* Augment data (brightness, rotation, slight blur) for robustness

> Place raw data under `data/` in subfolders like `eyes_open/`, `eyes_closed/`, `yawn/`, `no_yawn/` (or adapt `train.py` to your structure).

---

## ğŸ§  Training (Optional)

Fine-tune or train from scratch:

```bash
python src/train.py \
  --data_dir ./data \
  --epochs 25 \
  --batch_size 32 \
  --img_size 224 \
  --lr 1e-4 \
  --output_dir ./models
```

Outputs: model checkpoints and training logs in `models/`.

---

## ğŸ”Š Alerts

When the predicted drowsiness score exceeds the threshold, an alarm plays.
Change the sound or add other actuators (e.g., seat vibration, haptic) in `src/utils.py`.

---

## ğŸ§ª Notes & Troubleshooting

* Ensure good lighting for reliable eye/mouth detection.
* If FPS is low, switch to a lighter backbone (e.g., MobileNet) or reduce image size.
* On laptops with dual GPUs, make sure TensorFlow uses the intended GPU (if available).

---

## ğŸ¯ Roadmap / Future Work

* On-device/edge deployment (Jetson, Raspberry Pi)
* Multi-driver support & ID tracking
* Sensor fusion (eye aspect ratio + head pose + PERCLOS)
* Improved robustness with larger, diverse datasets

---

## ğŸ¤ Contributing

Contributions are welcome!

1. Fork this repo
2. Create a feature branch: `git checkout -b feat/my-feature`
3. Commit: `git commit -m "Add my feature"`
4. Push: `git push origin feat/my-feature`
5. Open a Pull Request

---

## ğŸ“ License

This project is licensed under the **MIT License**. See `LICENSE` for details.

---

## ğŸ™ Acknowledgements

* OpenCV & TensorFlow/Keras communities
* Public datasets and prior research on driver monitoring
* Classic methods (Haar/Viola-Jones) and modern detectors (YOLO) for ROI extraction

```
```
